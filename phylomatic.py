import click
import multiprocessing
import subprocess
import asyncio
import shlex
import sys
from functools import reduce, partial
import configparser
import re
import os
from pkg_resources import Requirement, resource_filename
from config import config_types


# ==================================== GLOBAL VARIABLES ====================================
devnull = open(os.devnull, 'w')  # so we can suppress the output of subprocesses


# Get the configuration variables from the config.ini file
CONFIG_FILE = resource_filename(Requirement.parse("phyl-o-matic"), "config.ini")
config_data = configparser.ConfigParser()
config_data.read(CONFIG_FILE)

CHECK_FREQ = float(config_data['default']['check_freq'])

MAX_GEN_DISCARD = int(config_data['generations']['max_discard'])
MIN_CYCLES = int(config_data['generations']['min_cycles'])

TRACECOMP_OUT_FILE = config_data['output']['tracecomp']
LOGLIK_LINE = int(config_data['output']['loglik_line'])

BPCOMP_OUT_FILE = config_data['output']['bpcomp']
MAX_DIFF_LINE = int(config_data['output']['max_diff_line'])

TREE_SAMPLE_FREQ = int(config_data['default']['tree_sample_freq'])


# Detect the number of cores on the machine (that we can use for the chain runs)
N_THREADS = multiprocessing.cpu_count()

# CLI defaults:
MAX_GEN = int(config_data['thresholds']['max_gen'])
MIN_LOGLIK_REL_DIFF = float(config_data['thresholds']['min_loglik_rel_diff'])
MAX_LOGLIK_EFFSIZE = int(config_data['thresholds']['max_loglik_effsize'])
MIN_MAXDIFF = float(config_data['thresholds']['min_maxdiff'])


# Input file types
# These are the alignment file types that the [run] command will look for when given a directory path
INPUT_FILE_TYPES = config_data['input']['filetypes'].split(', ')


# Output locations
# The name of the logfile
LOGFILE = 'alignments.log.csv'
# The name of the tree file generated by [bpcomp]
TREE_FILE_NAME = 'bpcomp.con.tre'
# The default directory to store the output in
OUTPUT_DIRECTORY = config_data['output']['directory']


# Output file data
# These are the chain file types that the [run] command will move to the [analyses] directory when a chain has been
# terminated
CHAIN_FILE_TYPES = ['.chain', '.monitor', '.param', '.run', '.trace', '.treelist']


def new_tree_file_name(alignment):
    """
    Return the new file name to use when renaming the default tree generated by [bpcomp].

    :param alignment: The name of the alignment (usually the name of the file without the .phy)
    """
    return '%s.tre' % alignment


def every(lst, fn):
    """
    Apply a function returning a boolean to every element of a list; return True if the function returns True for every
    element, and False if it returns False for at least one element.

    :param lst: The list to apply the function to.
    :param fn: The function to apply. This function must return a boolean.
    """
    return reduce(lambda acc, elem: acc and fn(elem), lst, True)


def trace_file_len(fname):
    """
    Return the number of generations in a chain trace file. If the file does not exist, return 0.

    :param fname: The path to the chain trace file.
    """
    try:
        with open(fname) as f:
            for i, l in enumerate(f):
                pass
        return i - 1
    except FileNotFoundError:
        return 0


def data_from_tracecomp_file():
    """
    Parse out and return data from the summary file generated by the [tracecomp] command. Currently this is the log
    likelihood effective size, and the log likelihood relative difference.
    """
    data = ''  # assume file will have more thant [MAX_DIFF_LINE] lines
    with open(TRACECOMP_OUT_FILE) as f:
        for i, line in enumerate(f):
            if i == LOGLIK_LINE:
                data = line

    parsed_data = re.sub(r'\s+', ' ', data).split(' ')
    loglik_effsize = int(parsed_data[1])
    loglik_rel_diff = float(parsed_data[2])
    return loglik_effsize, loglik_rel_diff


def data_from_bpcomp_file():
    """
    Parse out and return data from the summary file generated by the [bpcomp] command. Currently this is just the max
    difference.
    """
    data = ''  # assume file will have more thant [LOGLIK_LINE] lines
    with open(BPCOMP_OUT_FILE) as f:
        for i, line in enumerate(f):
            if i == MAX_DIFF_LINE:
                data = line

    parsed_data = re.sub(r'\s+', ' ', data).split(' ')
    max_diff = float(parsed_data[2])
    return max_diff


def create_logfile(output_dir, chains):
    """
    Create the CSV logfile, and populate it with column names for each of the summary statistics and each chain.

    :param output_dir: The output directory (where the output files are being moved to).
    :param chains: A list of the names of the chains being run.

    Preconditions:
        - output directory must exist
    """
    with open(os.path.join(output_dir, LOGFILE), 'w+') as f:
        chain_columns = ', '.join(chains)
        f.write('alignment, converged, loglik_effsize, loglik_rel_diff, max_diff, ' + chain_columns)


def add_row_to_logfile(output_dir, *args):
    """
    Add a CSV row to the logfile, given summary statistics and chain generation values.

    :param output_dir: The output directory (where the output files are being moved to).
    :param args: The name of the alignment, and the summary statistics, in the same order as the columns of the logfile
    as generated by [create_logfile].

    Preconditions:
        - [create_logfile] must have been called prior to the calling of this function
    """
    with open(os.path.join(output_dir, LOGFILE), 'a') as f:
        args_as_strings = map(str, args)
        f.write('\n' + ', '.join(args_as_strings))


def discard_samples(chain_length):
    """
    Calculate the number of generations to discard when running [tracecomp] or [bpcomp].

    :param chain_length: The current length of the chains. Although the chains will have different lengths, as long as
    the number of threads given to each chain is the same they should be roughly equal. Therefore, the length of any one
    of the chains is a good estimate.
    """
    return min(chain_length / 10, MAX_GEN_DISCARD)


class Convergence(object):
    """
    The container class for the chain summary/convergence statistics.
    """
    def __init__(self, stop, converged, loglik_effsize, loglik_rel_diff, max_diff, generations):
        """
        :param stop: True if the chains are to be terminated, False if not.
        :param converged: True if the chains is to be terminated due to convergence, False if not.

        Summary statistics:
        :param loglik_effsize: The log likelihood effective size.
        :param loglik_rel_diff: The log likelihood relative difference.
        :param max_diff: The maximum difference.
        :param generations: The number of generations the chains have reached. This is to be a dictionary of the
        following form:
        {
            'chain_1_name': length,
            'chain_2_name': length,
            et cetera
        }
        """
        self.stop = stop
        self.converged = converged
        self.loglik_effsize = loglik_effsize
        self.loglik_rel_diff = loglik_rel_diff
        self.max_diff = max_diff
        self.generations = generations

    def as_list(self):
        """
        Returns the summary statistics in list form, in the following order:
        [converged?, log likelihood effective size, log likelihood relative difference, maximum difference]
        """
        return [self.converged, self.loglik_effsize, self.loglik_rel_diff, self.max_diff]

    def print_data(self):
        """
        Print a message for the user detailing the summary statistics.
        """
        for chain, gen in self.generations.items():
            print('Generations for chain %s: %d' % (chain, gen))
        print('Log likelihood effective size: %d' % self.loglik_effsize)
        print('Log likelihood relative difference: %f' % self.loglik_rel_diff)
        print('Max diff: %f' % self.max_diff)


def chain_full_name(alignment, chain):
    """
    Return the full name of a chain, composed of the chain name and the alignment name, to be used for the chain files.

    :param alignment: The name of the alignment.
    :param chain: The name of the chain.
    """
    return '%s_%s' % (alignment, chain)


def check_thresholds(alignment, chains, min_cycles, max_gen, max_loglik_effsize, min_loglik_rel_diff, min_maxdiff):
    """
    Check if the termination thresholds have been satisfied. This can come about in two ways:
        - The chains have converged (the convergence thresholds have *all* been broken).
        - The chains have run for too long without converging (the chains have *all* exceeded the maximum number of
        generations).
    After checking, return an instance of [Convergence], with the summary statistics and termination information.

    Note that this function does *not* perform the check, and returns [None], if the minimum number of generations has
    not been reached by *all* of the chains.

    :param alignment: The name of the alignment.
    :param chains: A list of the names of the chains being run.
    :param min_cycles: The minimum number of generations the chains must have before checking for convergence.
    :param max_gen: The maximum number of generations for the chains to run before terminating regardless of
    convergence. Termination happens only when *all* of the chains have reached beyond this point.

    Convergence thresholds:
    :param max_loglik_effsize: The maximum log likelihood effective size.
    :param min_loglik_rel_diff: The minimum log likelihood relative difference.
    :param min_maxdiff: The minimum maximum difference.

    Preconditions:
        - the chains have equal numbers of threads allocated to them
    """
    if trace_file_len('%s.trace' % chain_full_name(alignment, chains[0])) < min_cycles:
        return None
    else:
        all_generations = {}
        above_max_gen = True
        g = 0
        for chain in chains:
            generations = trace_file_len('%s.trace' % chain_full_name(alignment, chain))
            all_generations[chain] = generations
            g = generations
            above_max_gen = above_max_gen and (generations > max_gen)

        chain_full_names = [chain_full_name(alignment, chain) for chain in chains]

        # we can assume that all the chains have progressed about the same amount, so pick one of the generation values
        discard = discard_samples(g)
        subprocess.call('tracecomp -x %d %s' % (discard, ' '.join(chain_full_names)),
                        shell=True, stdout=devnull, stderr=devnull)  # suppress output

        # the results get written to a file
        loglik_effsize, loglik_rel_diff = data_from_tracecomp_file()
        # have the thresholds been broken?
        loglik_effsize_broken = loglik_effsize > max_loglik_effsize
        loglik_rel_diff_broken = loglik_rel_diff < min_loglik_rel_diff

        subprocess.call('bpcomp -x %d %d %s' % (discard, TREE_SAMPLE_FREQ, ' '.join(chain_full_names)),
                        shell=True, stdout=devnull, stderr=devnull)  # suppress output

        # once again the results are written to a file
        max_diff = data_from_bpcomp_file()

        # have the thresholds been broken?
        max_diff_broken = max_diff < min_maxdiff

        # print('Thresholds: max loglik %d, min loglik rel diff %f, min maxdiff %f'
        #       % (max_loglik_effsize, min_loglik_rel_diff, min_maxdiff))
        # print('Broken: %d %d %d' % (loglik_effsize_broken, loglik_rel_diff_broken, max_diff_broken))

        converged = loglik_effsize_broken and loglik_rel_diff_broken and max_diff_broken
        stop = above_max_gen or converged
        return Convergence(stop, converged, loglik_effsize, loglik_rel_diff, max_diff, all_generations)


async def check_thresholds_periodic(alignment, chains, callback, check_freq, min_cycles, **thresholds):
    """
    Periodically check for convergence using [check_thresholds], waiting a set amount of time before each check.

    :param alignment: The name of the alignment.
    :param chains: A list of the names of the chains b eing run.
    :param callback: The callback function to call when the threshold check has failed, for whatever reason. This
    function must take the [Convergence] instance generated by the check as its first and only argument.
    :param check_freq: How often to perform the check (in seconds).
    :param min_cycles: The minimum number of generations the chains must have before checking for convergence.
    :param thresholds: The convergence thresholds to be used by [check_thresholds]. For details check the documentation
    of the former.

    Preconditions:
        - the chains have equal numbers of threads allocated to them
    """
    while True:
        result = check_thresholds(alignment, chains, min_cycles, **thresholds)
        # None indicates that the minimum number of cycles has not yet been reached
        if result is None or not result.stop:
            if result is not None:
                # print some data for the user
                result.print_data()
                print('')  # new line

            await asyncio.sleep(check_freq)
            continue
        else:
            # print some data for the user
            result.print_data()
            print('')  # new line
            callback(result)
            break


def mpirun_cmd(threads, phyle_name, chain_name):
    """
    Return the [mpirun] command to execute given an alignment and a chain.

    :param threads: The number of threads to run the chain on.
    :param phyle_name: The *full* name of the alignment file to process.
    :param chain_name: The *full* name of the chain.
    """
    # Get it? Phyle name? .phy file name?
    return shlex.split('mpirun -np %d pb_mpi -cat -gtr -dgam 4 -d %s %s' % (threads, phyle_name, chain_name))


def terminate_all_processes(processes):
    """
    Terminate all the processes in a list. Note that this sends a SIGTERM rather than a SIGKILL, allowing each process
    to exit gracefully.

    :param processes: The list of processes to terminate.
    """
    for process in processes:
        process.terminate()


def move_output_files(output_dir, tree_dir, alignment, save_run):
    """
    After the chains have finished running, move the chain output files and the generated tree file to their places in
    the output directory.

    :param output_dir: The path to the output directory.
    :param tree_dir: The directory to move the tree file to.
    :param alignment: The name of the alignment.
    :param save_run: True if the output chain files from this run are to be kept, False if they are to be deleted.

    Preconditions:
        - the [run] command must have been executed prior to calling this function.
    """
    # Create output directory, and subdirectories: analyses, good_trees, bad_trees
    analyses_dir = os.path.join(output_dir, 'analyses', alignment)

    if not os.path.exists(analyses_dir):
        os.makedirs(analyses_dir)

    if save_run:
        if not os.path.exists(tree_dir):
            os.makedirs(tree_dir)

        # Move chain files into output/analyses/[alignment]: .chain, .monitor, .param, .run, .trace, .treelist
        for file_type in CHAIN_FILE_TYPES:
            for file in os.listdir('.'):
                if file.endswith(file_type):
                    current_path = os.path.join('.', file)
                    new_path = os.path.join(analyses_dir, file)
                    os.rename(current_path, new_path)
    else:
        # delete all run files
        for file_type in CHAIN_FILE_TYPES:
            for file in os.listdir('.'):
                if file.endswith(file_type):
                    os.remove(file)

    # Move and rename output tree file
    os.rename(TREE_FILE_NAME, os.path.join(tree_dir, new_tree_file_name(alignment)))


def check_fail_callback(convergence, alignment, chains, processes, output_dir, save_good_tree_runs):
    """
    This is the function that is called when the threshold check fails. All but the first arguments are intended to be
    bound to the function using [functools.partial] to create a callback that fits the specification outlined in
    [check_thresholds_periodic].

    :param convergence: The [Convergence] instance generated by the check.
    :param alignment: The name of the alignment.
    :param chains: A list of the names of the chains being run.
    :param processes: A list of the [mpirun] processes running the chains.
    :param output_dir: The output directory (where the output files are being moved to).
    :param save_good_tree_runs: True if output chain files from good trees are to be kept, False if they are to be
    deleted.
    """
    # Stop all chain runs
    terminate_all_processes(processes)

    # Write output data to the log
    generations_list = [0 for i in convergence.generations.items()]
    for chain, generations in convergence.generations.items():
        i = chains.index(chain)
        generations_list[i] = generations

    log_data = [alignment] + convergence.as_list() + generations_list
    add_row_to_logfile(output_dir, *log_data)

    # Now we need to move the output files to the correct directories

    # If the chains converged, move the output tree file to good_trees, otherwise move it to bad_trees
    # Also, rename it to [alignment].tre
    save_run = True
    if convergence.converged:
        # do we save the runs?
        if not save_good_tree_runs:
            save_run = False
        tree_dir = os.path.join(output_dir, 'good_trees')
    else:
        save_run = True
        tree_dir = os.path.join(output_dir, 'bad_trees')

    move_output_files(output_dir, tree_dir, alignment, save_run)


def apply_decorators(*decorators):
    """
    Return a decorator that is equivalent to applying a list of decorators, in order.

    :param decorators: The list of decorators to merge.
    """
    def dec(fn):
        for d in reversed(decorators):
            fn = d(fn)
        return fn
    return dec


@click.group()
def cli():
    pass


@cli.command()
@click.option('--threads', type=int, default=N_THREADS,
              help='How many threads the process should run on. Default: %d.' % N_THREADS)
@click.option('--max-gen', type=int, default=MAX_GEN,
              help='The maximum number of generations to run the process for. Default: %d.' % MAX_GEN)
@click.option('--min-loglik-rel-diff', type=float, default=MIN_LOGLIK_REL_DIFF,
              help='Threshold log likelihood relative difference. Default: %f.' % MIN_LOGLIK_REL_DIFF)
@click.option('--max-loglik-effsize', type=int, default=MAX_LOGLIK_EFFSIZE,
              help='Threshold log likelihood effective size difference. Default: %d.' % MAX_LOGLIK_EFFSIZE)
@click.option('--min-maxdiff', type=float, default=MIN_MAXDIFF,
              help='Threshold maximum difference. Default: %f.' % MIN_MAXDIFF)
@click.option('--check-freq', type=float, default=CHECK_FREQ,
              help='How often to check for convergence (in seconds). Default: %f.' % CHECK_FREQ)
@click.option('--min-cycles', type=int, default=MIN_CYCLES,
              help='How many generations to ignore before checking for convergence. Default: %d.' % MIN_CYCLES)
@click.option('--out', type=str, default=OUTPUT_DIRECTORY,
              help='The directory to store the output files in. Default: %s.' % OUTPUT_DIRECTORY)
@click.option('--save-good-tree-runs', is_flag=True,
              help='Save the run files for good trees as well as bad trees. If disabled, only bad tree runs are saved.')
@click.argument('alignments', type=click.Path(exists=True), required=True, nargs=-1)
@click.argument('chains', type=int, required=True)
def run(threads, alignments, chains, check_freq, min_cycles, out, save_good_tree_runs, **thresholds):
    """
    ALIGNMENTS: the paths to the alignment files to process. The alignments will be processed sequentially, and not in
    parallel. To process in parallel, run several instances of this command, adjusting the number of threads
    accordingly.

    Alternatively, the paths can be to directories. In that case, all files of the relevant file type in the directory
    will be processed sequentially. The file types that the command accepts can be set in the configuration file.

    CHAINS: the number of the chains to run in parallel. Threads will be shared evenly among the chains. The number of
    chains must be at least two, but cannot be greater than the number of threads allocated.
    """
    click.echo(save_good_tree_runs)
    if chains < 2:
        print('Error: Must specify at least two chains.')
        sys.exit(1)
    elif chains > threads:
        print('Error: The number of chains cannot be less than the number of threads allocated.')
        sys.exit(1)
    else:
        # generate some chain names
        chain_names = [('chain_%d' % (j + 1)) for j in range(chains)]
        print('Chains: %s' % ', '.join(chain_names))
        # create the output directory
        os.mkdir(out)
        # create a logfile
        create_logfile(out, chain_names)

        alignment_files = []
        for path in alignments:
            if os.path.isfile(path):
                alignment_files.append(path)
            else:
                for file in os.listdir(path):
                    for file_type in INPUT_FILE_TYPES:
                        if file.endswith(file_type):
                            alignment_files.append(file)

        # sequentially process each alignment
        for alignment in alignment_files:
            processes = []
            threads_per_chain = threads / chains
            alignment_file_name_without_extension = os.path.splitext(alignment)[0]

            # generate specific chain file names
            chain_full_names = [chain_full_name(alignment_file_name_without_extension, chain_name)
                                for chain_name in chain_names]

            try:
                for chain_name in chain_full_names:
                    cmd = mpirun_cmd(threads_per_chain, alignment, chain_name)
                    click.echo('Starting run: %s' % ' '.join(cmd))
                    # open it and start running
                    process = subprocess.Popen(cmd)
                    processes.append(process)

                callback = partial(check_fail_callback,
                                   alignment=alignment_file_name_without_extension,
                                   chains=chain_names,
                                   processes=processes,
                                   output_dir=out)

                # This event loop blocks execution until it's done, thus preventing the next alignment from being
                # processed until this one is done:
                loop = asyncio.get_event_loop()
                loop.run_until_complete(check_thresholds_periodic(
                    alignment_file_name_without_extension, chain_names, callback, check_freq, min_cycles, **thresholds))

                print('Alignment %s chains finished processing.' % alignment_file_name_without_extension)
            except BaseException:  # so that it catches KeyboardInterrupts
                # Upon an exception:
                # 1. Stop all chains
                # 2. Move all chain output files to output/analyses
                # 3. Move output tree file to output/incomplete_trees

                # Step 1:
                print('Exception raised, terminating all chains...')
                terminate_all_processes(processes)

                # Steps 2 & 3:
                print('Saving output files...')
                tree_dir = os.path.join(out, 'incomplete_trees')

                # Save runs because the tree is incomplete
                move_output_files(out, tree_dir, alignment, True)
                raise

            print('All alignment chains finished.')


# Create the list of option decorators for the [config] command: one for each configuration variable.
config_cmd_decorators = []
for category, variables in config_data.items():
    for variable, value in variables.items():
        full_variable_name = '%s-of-%s' % (variable, category)
        current_value = config_data[category][variable]
        decorator = click.option(
            '--%s' % full_variable_name,
            type=config_types[category][variable],
            default=None,
            help='Set the configuration variable %s. Current value: %s.' % (full_variable_name, current_value)
        )
        config_cmd_decorators.append(decorator)


@cli.command()
@apply_decorators(*config_cmd_decorators)
def config(**config_variables):
    for var, val in config_variables.items():
        if val is not None:
            name, cat = var.split('_of_')
            config_data[cat][name] = val

    with open(CONFIG_FILE, 'w') as configfile:
        config_data.write(configfile)
